\section{Procesos ETL}\label{section:etl}

ETL son las siglas de  Extract, Transform, Load, en español Extraer, Transformar y Cargar. Es un proceso fundamental en la 
integración y gestión de datos. Implica extraer datos desde varios or\'igenes, generalmente con formatos distintos, 
conciliarlos, mediante tecnicas de transformación y validaci\'on, en un formato compatible con un almacenamiento destino 
predefinido y luego cargarlos en dicho sistema destino. Lo que permite aumentar la cantidad y la calidad de los datos 
disponibles para los an\'alisis adem\'as de permitir la integración con sistemas heredados. ETL est\'a presente en la 
industria desde la década de 1970 y empez\'o a ganar popularidad con el auge de los almacenes de datos\cite{etl_vs_elt_amazon}.

\subsection{Objetivos de los procesos ETL}

El objetivo fundamental de los procesos ETL es garantizar la calidad, consistencia y confiabilidad de los datos para 
fines anal\'iticos y de toma de decisiones. Adem\'as, cumple con otros objetivos clave. En una primera instancia, 
tienen el objetivo de consolidar datos de m\'ultiples fuentes, d\'igase bases de datos, hojas de c\'alculo, APIs, 
archivos planos y sistemas externos, en un formato unificado y estandarizado. La consolidación de los datos facilita 
los procesos de an\'alisis y de generación de informes de datos. En segundo lugar, con los procesos ETL se busca 
limpiar y transformar los datos, asegurando que sean precisos, completos y cumplan con las reglas y requisitos comerciales. 
Por \'ultimo, ETL permite la integración con datos en tiempo real e históricos, lo cual brinda a las organizaciones una visión 
completa de sus datos a lo largo del tiempo, mejorando la obtenci\'on de conocimiento y la toma de decisiones.

\subsection{ETL vs ELT}

Extraer, Cargar y Transformar, ELT por sus siglas en ingl\'es es un proceso derivado de ETL solo que invierte las operaciones 
de carga y transformación. En ELT se cargan los datos en el sistema destino justo despu\'es de ser extra\'idos de la fuente 
o\'igen. La transformaciónde los datos extr\'idos es responsabilidad del sistema destino. La mayor parte de las 
transformaciones se realizan en la etapa de análisis y se cargan los datos en bruto mínimamente procesados en el 
almacenamiento de datos.

El uso m\'as tipico de ELT yace en el \'ambito del Big Data\cite{raunakjhawar_ETL_microsoft}. La adopción de la 
infraestructura en la nube, que proporciona a las bases de datos de destino la potencia de procesamiento necesaria 
para realizar las transformaciones, hacen que la variante ELT sea elegida cada vez con m\'as frecuencia.

Comparando ambos enfoques, con ELT se simplifica la arquitectura pues se elimina del proceso el motor de transformación. 
Tambi\'en, al escalar el almacenamientode datos de destino también se escala el rendimiento del proceso ELT pues es all\'i
donde se realizan las transformaciones. ELT omite el paso de copia presente en ETL que puede ser una operaci\'on muy costosa 
si el conjunto de datos es grande. Pero solo es efectivo usar este enfoque si el sistema destino es lo suficientemente
potente como para transformar los datos de manera eficiente.

Por otro lado, ETL es la mejor opci\'on para el tratamiento de datos estructurados\cite{etl_vs_elt_amazon}. Con 
ETL se transforma el formato de los datos, pero se mantiene su naturaleza estructurada. ETL es una tecnología madura 
con m\'as de 20 años de explotaci\'on, sus protocolos y buenas pr\'acticas son conocidos y bien documentados. Como principal 
desventaja le acompaña el hecho de que requiere m\'as definici\'on al principio, pues deben definirse los tipos de datos 
del destino, estructuras y relaciones.

\subsection{Operaciones de los Procesos ETL}

Como su nombre lo indica, las operaciones que conforman los Procesos ETL son:

\subsubsection{Extracci\'on}

Es el primer paso de ETL. En este paso se extraen datos desde m\'ultiples fuentes y se colocan en un \'area de preparaci\'on 
en donde ser\'an transformados. Cada fuente de datos puede usar una organizaci\'on diferente de los datos o formatos distintos. 
El proceso de extracci\'on debe generar un impacto m\'inimo en el sistema or\'igen, si se extraen muchos datos se podr\'ia 
exceder la capacidad de carga del r\'igen, provocando que colapse y no est\'e disponible para su uso. Por esta los grandes 
sistemas consumidores de datos programan sus actividades de extracci\'on para d\'ias u horarios donde su impacto sea 
m\'inimo. 

La frecuencia con la que se realiza la extracci\'on desde el or\'igen depende del mecanismo implementado de captura de datos 
modificados. Algunos sistemas or\'igen notifican cuando se ha cambiado un registro de datos. A continuaci\'on se ejecuta el 
proceso de extracci\'on para ese cambio. Algunos sistemas no son capaces de identificar cambios en los datos, por lo que 
la estrategia se simplifica a volver a extraer todos los datos del or\'igen.

\subsubsection{Transformaci\'on}

El paso de Tranformaci\'on es el encargado de consolidar los datos para prepararlos para el almacenamiento de datos destino. 
Esta fase puede implicar los siguientes tipos de cambios de datos:

\begin{itemize}
    \item Seleccionar solo algunas columnas para ser cargadas.
    \item Traducir c\'odigos (por ejemplo, si la fuente almacena una "M" para Masculino y "F" para Femenino pero el destino 
        tiene que guardar "1" para Masculino y "2" para Femenino)
    \item Codificar valores, ejemplo de esto es convertir "Principal" en "P" o "Secundario" en "S"
    \item Eliminar datos duplicados.
    \item Revisi\'on de los formatos de los datos. Un caso com\'un de esto es la conversi\'on de unidades de medida 
        o la conversi\'on de los formatos de fecha/hora.
\end{itemize}

También se pueden realizar transformaciones m\'as avanzadas, que siguen las reglas del negocio para optimizar los datos y 
facilitar los análisis:

\begin{itemize}
    \item Aplicar directamente reglas comerciales a los datos, por ejemplo convertir los ingresos en ganancias restando los 
        gastos.
    \item Vincular datos de diferentes or\'igenes. Por ejemplo, calcular el costo total de compra de un producto 
        sumando el valor de compra de los diferentes proveedores y almacenando solo el total final en el sistema de destino.
    \item Cifrar datos confidenciales para cumplir con las leyes de datos o de privacidad antes de cargar la informaci\'on 
        en el sistema destino.
\end{itemize}


\subsubsection{Carga}

La fase de Carga es el momento en que los datos resultantes de la fase de Transformaci\'on son cargados en sistema destino. 
En dependencia de los requisitos de cada organización, el proceso de carga abarca una variedad de acciones diferentes. 
En ocasiones se sobrescribe la información antigua de la bases de datos con nuevos datos. En cambio, los Almacenes de Datos 
conservan todos los datos con el objetivo de mantener un historial. La mayoría de las organizaciones que utilizan ETL, 
tienen este proceso automatizado, correctamente definido, continuo y por lotes\cite{ETL_amazon}. La carga de datos puede
ser de forma completa donde todos los datos de la fuente se transforman y se mueven al almacenamiento de datos, o bien 
puede ser de forma progresiva donde se carga la diferencia entre los sistemas de origen y destino a intervalos regulares.

\subsection{Herramientas para Procesos ETL}

Actualmente existen varias herramientas ETL en el mercado, cada una posee características propias y capacidades \'unicas. 
Entre las m\'as populares encontramos a Talend Data Fabric, Informatica PowerCenter, Fivetran, Stitch y Xplenty. Estas 
herramientas ofrecen gestión de datos basada en la nube, la integración basada en metadatos y soporte para varias bases 
de datos relacionales y no relacionales

Además de las opciones anteriores, existen varias opciones populares de c\'odigo abierto, como son Apache NiFi, AWS Glue 
e Informatica. Estas herramientas ofrecen casi todas las funcionalidades de sus contrapartes comerciales y a menudo 
son m\'as personalizables y flexibles.